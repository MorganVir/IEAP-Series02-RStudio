---
title: "IEAP-Series02-Rstudio: Correlation and statistical tests\n"
author: "Morgan VIROLAN"
date: "`r format(Sys.time(), '%d %B, %Y, %H:%M')`"
output:
  html_document:
    df_print: paged
    code_folding: hide
    toc: false
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Correlations and linear regression
In this series of exercises, we will explore correlations and linear regression, using a dataset from a real experiment.

## The problem
**We want to know if there is a relationship between the nonuse of the proximal part of the upper limb (PANU) and the nonuse of the shoulder (SANU) or the elbow (EENU).**

## The data
As we will see, the data is far from perfect, but this is the reality of experimental data, especially in the case of clinical data.

The file "NonUse.csv" contains measures of upper extremity nonuse:

- PANU: Proximal Arm Non Use
- SANU: Shoulder Antepulsion Non Use
- EENU: Elbow Extension Non Use

In the notebook, we'll make a clear description of the experiment, the variables and the data, providing the units of each variable, and the range of possible values.


```{r load-data and create descriptive table}
# loading knit for table generation down the line
library(knitr)
# loading the csv file
nonuse <- read.csv("data/test_data/NonUse.csv" , header = TRUE)
summary(nonuse) 


tbl_PaSaEe <- data.frame(
  Name = c("PANU", "SANU", "EENU"),
  Description = c(
    "Proximal Arm Non Use",
    "Shoulder Antepulsion Non Use",
    "Elbow Extension Non Use"
  ),
  unit = "%",
  range = "-100 to 100"
)

kable(tbl_PaSaEe, caption = "Table 1: Description of the variables in NonUse.csv")
```

## Correlation analysis

**Is PANU correlated with SANU and/or EENU?**

We use Spearman’s rank correlation because the data are clinical, not guaranteed to follow a normal distribution, and the relationships may be monotonic but not strictly linear.

```{r correlation tests}
cor.test(nonuse$PANU, nonuse$SANU, method = "spearman")
cor.test(nonuse$PANU, nonuse$EENU, method = "spearman")
```
- PANU and SANU show a weak but significant positive correlation (ρ = 0.22, p = 0.002, both values rounded up).
- PANU and EENU show a moderate and significant positive correlation (ρ = 0.39, p < 0.001, both values rounded up).

This means that higher proximal arm nonuse is associated with higher nonuse of the shoulder and elbow, with a stronger relationship at the elbow level.

**Visualize the PANU-SANU relationship (and the PANU-EENU relationship)**

```{r scatter plots visualisation of the relationships}
library(ggplot2)

ggplot(nonuse, aes(x = PANU, y = SANU)) +
  geom_point(na.rm = TRUE) +
  labs(title = "Scatter plot of PANU vs SANU",
       x = "PANU (%)", y = "SANU (%)") +
  coord_equal() +
  theme_minimal()

ggplot(nonuse, aes(x = PANU, y = EENU)) +
  geom_point(na.rm = TRUE) +
  labs(title = "Scatter plot of PANU vs EENU",
       x = "PANU (%)", y = "EENU (%)") +
  coord_equal() +
  theme_minimal()

```

**Perform a linear regression for PANU-SANU (and for PANU-EENU)**

We do not predict a linear relationship between the variables but we do as we are asked. 

```{r plot-sanu-lm}
library (ggplot2)

ggplot(nonuse, aes(x = SANU, y = PANU)) +
  geom_point(na.rm = TRUE) +
  geom_smooth(method = "lm", se = TRUE, color = "blue") +
  labs(title = "Scatter plot of PANU vs SANU with regression line",
       x = "SANU (%)",
       y = "PANU (%)") +
  coord_equal() + # auto scale, to have the same scale on both axis
  theme_minimal()

ggplot(nonuse, aes(x = EENU, y = PANU)) +
  geom_point(na.rm = TRUE) +
  geom_smooth(method = "lm", se = TRUE, color = "blue") +
  labs(title = "Scatter plot of PANU vs EENU with regression line",
       x = "EENU (%)",
       y = "PANU (%)") +
  coord_equal() + # auto scale, to have the same scale on both axis
  theme_minimal()
```


**Give the regression equations: PANU = a * SANU + b and PANU = a * EENU + b**

```{r}
lm_sanu <- lm(PANU ~ SANU, data = nonuse)
summary(lm_sanu)
coef(lm_sanu)
slope <- coef(lm_sanu)[2]
intercept <- coef(lm_sanu)[1]
cat("The regression equation is: PANU =", round(slope,3), "* SANU +", round(intercept,2), "\n")

lm_eenu <- lm(PANU ~ EENU, data = nonuse)
summary(lm_eenu)
coef(lm_eenu)
slope <- coef(lm_eenu)[2]
intercept <- coef(lm_eenu)[1]
cat("The regression equation is: PANU =", round(slope,3), "* EENU +", round(intercept,2), "\n")

```

The linear model PANU ~ SANU :

$$
PANU = 0.101 \times SANU + 8.87
$$

This relationship was not statistically significant (p = 0.171) and explained less than 1% of the variance (R² = 0.009), indicating very weak predictive power.  

The model PANU ~ EENU :

$$
PANU = 0.399 \times EENU + 5.67
$$

This relationship was statistically significant* (p < 0.001) and explained about 22% of the variance (R² = 0.225), suggesting a modest but meaningful association between proximal arm nonuse and elbow extension nonuse.


**Summarize your results as you would do in your master’s thesis report, or as in a scientific article (e.g., What sentence will you write in the article explaining your result?).**

Spearman’s correlations showed that proximal arm nonuse (PANU) was weakly but significantly associated with shoulder antepulsion nonuse (SANU; ρ = 0.22, p = 0.002, n ≈ 209) and moderately and significantly associated with elbow extension nonuse (EENU; ρ = 0.39, p < 0.001, n ≈ 209).

In linear regressions, SANU did not significantly predict PANU (β = 0.101, p = 0.171; R² = 0.009), whereas EENU did (β = 0.399, p < 0.001; R² = 0.225). Thus, greater proximal arm nonuse relates more strongly to elbow extension nonuse than to shoulder antepulsion nonuse.

**What are the limits of your analysis?**

The main limitations are the large number of missing values (223 rows removed), the weak explanatory power of the shoulder model, and the assumptions of linear regression which may not be fully met with this clinical dataset. Importantly, the associations observed are correlational and do not imply causality.

# Statistical tests: comparison of medians (or means?)
In this series of exercises, we will explore how to compare two groups of data, using non-parametric tests (or parametric tests… if it makes sense to do so).

## Make clear what is a statistical test, and when to use it.
**Below are some questions to guide the analysis.**

For this part, i used an LLM (gpt 5) because some of these concepts are universal, non-controversial, and always defined the same way across sources. 

Prompt used:
“Give me short and clear answer for the following: What is a mean? What is a median? [...] Each answer should be concise, one to two sentences.”

- **Mean**: The arithmetic average, obtained by summing all observations and dividing by the number of values.  
- **Median**: The middle value of an ordered dataset, with half of the values below and half above.  
- **Variance**: Measures how spread out the data are by averaging the squared deviations from the mean.  
- **Standard deviation**: The square root of the variance, providing a measure of spread in the same units as the data.  
- **Statistical test**: A procedure used to evaluate a hypothesis, determining whether observed results are compatible with a null hypothesis.  
- **When to use a statistical test**: Used to assess whether an observed difference or association is likely due to chance or reflects a real effect.  
- **Parametric test**: Assumes the data follow a specific distribution (usually normal) and rely on parameters like mean and variance.  
- **Non-parametric test**: Makes no strict assumptions about the data’s distribution and is often based on ranks or medians.  
- **Paired vs unpaired tests**: A paired test compares two related measurements from the same subjects (e.g., before/after), while an unpaired test compares two independent groups.  


The next items required a more thorough investigation. An LLM was used for some light rephrasing and grammar correction and formating, but not for the content itself.

- **Normal distribution (or Gaussian)**: A symmetric, bell-shaped distribution centered on the mean, where ~68% of values lie within one standard deviation and 95% within two; its importance comes from many sample statistics being normally distributed (Bruce, Bruce & Gedeck, 2020).  

- **Assumption of normality**: Requires that the data (or more precisely, the residuals) follow a normal distribution. In practice, this condition is rarely fully satisfied and is often treated as a last resort (Bruce, Bruce & Gedeck, 2020).  

- **p-value**: The probability of obtaining results at least as extreme as those observed if the null hypothesis (no effect) were true. A small p-value means the data would be unlikely under this assumption, which may suggest evidence against it. However, it does not give the probability that the null is true or false. It does not measure the effect size (Amrhein, Greenland & McShane, 2019).  

- **Risk of error in statistical tests**:  (Shreffler & Huecker, 2023)
  - *Type I error (α)*: Concluding there is an effect when in truth there is none : false positive.  
  - *Type II error (β)*: Failing to detect a real effect : false negative. 

- **Assumptions of parametric tests**: Data are drawn from populations following a normal distribution, observations are independent, and group variances are equal. These assumptions allow estimation of parameters such as means and standard deviations. If violated, the validity of the test may be compromised (Nahm, 2016).  

- **Assumptions of non-parametric tests**: Require fewer assumptions; mainly independence of observations and that data can be ordered or ranked. Useful when data are skewed, variances are unequal, or sample sizes are too small to meet parametric requirements (Nahm, 2016).  

--- 

References :

- Amrhein, V., Greenland, S., & McShane, B. (2019). Retire statistical significance. *Nature*, 567(7748), 305–307.  
- Bruce, P., Bruce, A., & Gedeck, P. (2020). Practical statistics for data scientists: 50 essential concepts (2nd ed.). O’Reilly Media.  
- Dorey, F. (2011). Statistics in brief: Interpretation and use of p values: All p values are not equal. Clinical Orthopaedics and Related Research, 469(6), 1819–1821.  
- Nahm, F. S. (2016). Nonparametric statistical tests for the continuous data: The basic concept and the practical use. Korean Journal of Anesthesiology, 69(1), 8–14. https://doi.org/10.4097/kjae.2016.69.1.8  
- Shreffler, J., & Huecker, M. R. (2023). Type I and Type II errors and statistical power. In StatPearls. StatPearls Publishing. https://www.ncbi.nlm.nih.gov/books/NBK557530/  



## Effect of treatment over time
This is a very classical question in clinical or sport research: does a treatment-training have an effect over time?

To answer this question scientifically, measurements must be taken before and after treatment, and possibly later, in order to assess whether the effect is lasting or not.

### The data

This file "PrePost.csv" contains before/after measurements. The treatment is a rehabilitation training for individuals with cardiac conditions.

```{r loading-PrePost}
prepost <- read.csv("data/test_data/PrePost.csv", header = TRUE)

# overview of the structure comented out since it creates a lot of output and was used only for testing purpose. left for legacy
# str(prepost)
# summary(prepost)
# head(prepost)

```

```{r table-of-the-prepost-variables}
tbl_prepost <- data.frame(
  Variable = c("perf", "time"),
  Description = c("Performance measurement", 
                  "Measurement of time (Before vs After rehab. protocol)"),
  Unit = c("Arbitrary units (AU)",
           "Categorical (factor)"),
  `Possible values` = c("Approx. 120-150", "Before / After"),
  `Expected change` = c("Increase after rehabilitation", "-")
)

kable(tbl_prepost, caption = "Table 2: Description of the PrePost.csv variables")

```

Performance measurement could represent either maximum workload (W) or maximum heart rate (HRMax, bpm) reached during a functional test. 

Even though the exact population differs (stable coronary artery disease, slightly older patients), studies such as Hambrecht et al. (2004) show that maximum workload and maximum heart rate are commonly reported outcomes with cardiac patients, with values in a similar range to those observed in our dataset. For example, in their trial, patients improved their maximal heart rate from 131 ± 3 bpm to 137 ± 3 bpm and their work capacity from 133±5 W to 159±5.

Reference : 

- Hambrecht, R., Walther, C., Mobius-Wrinkler, S., Gielen, S., Linke, A., Sabri, O., et al. (2004). Percutaneous coronary angioplasty compared with exercise training in patients with stable coronary artery disease: A randomized trial. Circulation, 109(11), 1374–1380. https://doi.org/10.1161/01.CIR.0000121360.31954.1F


### The analysis
We now want to know if the treatment has an effect on one or more of the measured variables.

**Does the treatment have an effect?**

We want to compare before vs after rehab on the perf variable. If values increased significantly, it suggests an effect.


**What comparison are we going to make?**

Since it's the same patients that were measured twice (Before / After the rehab), this is a paired comparison:

  - Null hypothesis H₀: no difference in perf between before and after.
  - Alternative hypothesis H₁: perf after > perf before.

**Which test will you use? Parametric or non-parametric?**

```{r}
library(moments)  # for skewness & kurtosis

# Differences
diffs <- with(prepost, perf[time == "After"] - perf[time == "Before"])

# Shapiro-Wilk test
shapiro.test(diffs)

# Skewness and kurtosis
skew_val <- skewness(diffs)
kurt_val <- kurtosis(diffs)

cat("Skewness:", round(skew_val, 2), "\n")
cat("Kurtosis:", round(kurt_val, 2), "\n")

# Plots
par(mfrow = c(1, 2))
hist(diffs, main = "Histogram of differences", xlab = "After - Before", col = "lightblue", border = "white")
qqnorm(diffs, main = "Q-Q Plot of differences")
qqline(diffs, col = "red")
par(mfrow = c(1, 1))

```

We checked normality with Shapiro–Wilk (W = 0.90, p = 0.283). Skewness (0.61), kurtosis (2.75), and the plots also looked fine. 

Following Razali & Wah (2011), we added these checks, but with only n = 8 normality tests have little power (Razali & Wah, 2011; Ghasemi & Zahediasl, 2012). 

So we went with the Wilcoxon signed-rank test, which fits our hypothesis (paired differences) and is safer with small samples (McDonald, 2014). 

Since we don’t really know what `perf` measures, we can’t be sure if higher or lower values mean improvement. To stay on the safe side, we used a two-sided Wilcoxon test to check for any effect of rehab in either direction, as recommended by UCLA’s FAQ (UCLA OARC, 2024).

References : 

- Ghasemi, A., & Zahediasl, S. (2012). Normality tests for statistical analysis: A guide for non-parametric methods. International Journal of Endocrinology and Metabolism, 10(2), 486–489. https://doi.org/10.5812/ijem.3505
- McDonald, J. H. (2014). Handbook of Biological Statistics (3rd ed., p. 32). Sparky House Publishing. http://www.biostathandbook.com
- Razali, N. M., & Wah, Y. B. (2011). Power comparisons of Shapiro–Wilk, Kolmogorov–Smirnov, Lilliefors and Anderson–Darling tests. Journal of Statistical Modeling and Analytics, 2(1), 21–33.
- UCLA: Statistical Consulting Group. (2024). FAQ: What are the differences between one-tailed and two-tailed tests? UCLA Institute for Digital Research and Education. Retrieved from https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-what-are-the-differences-between-one-tailed-and-two-tailed-tests/

```{r wilcoxong signed test}
wilcox.test(
  prepost$perf[prepost$time == "Before"],
  prepost$perf[prepost$time == "After"],
  paired = TRUE,
  alternative = "two.sided"
)

# Medians for reporting
tapply(prepost$perf, prepost$time, median)

```

The test showed a significant difference between Before and After (V = 0, p ≈ 0.014).
Median performance increased from 135.5 (Before) to 137.5 (After).

R gives a warning about ties (“exact p-value not computable with ties”), which occurred because several participants showed identical change scores. This leads to ties in the ranking of differences. In such cases, R automatically switches to an approximate p-value with continuity correction.


**Which graph illustrates the effect of the treatment?**

```{r spaghetti graph}
library(ggplot2)
library(dplyr)
library(tidyr)

# Reconstruct subject IDs because it's missing on the prepost.csv
prepost <- prepost %>%
  group_by(time) %>%
  mutate(row = row_number()) %>%
  tidyr::pivot_wider(names_from = time, values_from = perf) %>%
  mutate(id = row_number()) %>%
  tidyr::pivot_longer(cols = c("Before", "After"),
                      names_to = "time", values_to = "perf")

# Ensure proper order
prepost <- prepost %>%
  mutate(time = factor(time, levels = c("Before", "After")))

# Plot: 2 boxplots + spaghetti lines
ggplot(prepost, aes(x = time, y = perf)) +
  geom_boxplot(outlier.shape = NA, fill = "lightgray") +
  geom_line(aes(group = id), colour = "gray60", alpha = 0.7) +
  geom_point(size = 2) +
  labs(x = NULL,
       y = "Performance (AU)",
       title = "Performance Before and After Rehabilitation") +
  theme_minimal(base_size = 14)

```

Weissgerber et al. (2016) recommend showing individual-level data with paired line plots, since small sample studies can be misleading if only group summaries are reported. Following this, we used a spaghetti plot to display each participant’s trajectory. On top of that, we overlaid boxplots to also convey the group median and variability, which makes the figure a bit more loaded but provides a more complete view of the data.


Reference :

- Weissgerber, T. L., Milic, N. M., Winham, S. J., & Garovic, V. D. (2016). Beyond bar and line graphs: Time for a new data presentation paradigm. PLOS Biology, 14(4), e1002430. https://doi.org/10.1371/journal.pbio.1002128


**What sentence will you write in your thesis to explain your result?**

Participants showed a small but consistent improvement after rehabilitation, with all trajectories going upward and no ill or adverse effects. The Wilcoxon signed-rank test confirmed the change was significant (V = 0, p ≈ 0.014), with median values rising from 135.5 to 137.5 (Arbitrary Units as we could say for sure what was the actual performance metric). Assuming that higher perf reflects better functional capacity, this points to a positive effect of the program.


## Testing some stereotypes
Humans have stereotypes, some of them are probably true, some others are probably false (e.g., https://pmc.ncbi.nlm.nih.gov/articles/PMC9850150/).

Here, we will test stereotypes about snorers… among others.

### The data
This file contains anthropometric and qualitative measurements (1 person per line).

```{r data-load snore.txt}
snore <- read.table("data/test_data/snore.txt", header = TRUE)

# same as before : used for testing purpose, left for legacy
# str(snore)
# summary(snore)
# head(snore)

```

```{r}
tbl_snore <- data.frame(
  Variable = c("age", "weight", "height", "alcool", "sex", "snore", "tabac"),
  Description = c(
    "Age of participant",
    "Body weight",
    "Body height",
    "Alcohol consumption",
    "Sex (H = male, F = female)",
    "Snoring status (O = yes, N = no)",
    "Smoking status (O = yes, N = no)"
  ),
  Unit = c("Years", "kg", "cm", "Frequency score", "-", "-", "-"),
  `Possible values` = c("23-74", "42-120", "158-208", "0-15", "H/F", "O/N", "O/N")
)

knitr::kable(tbl_snore, caption = "Table 3: Description of the variables in snore.txt")

```


### The analysis
**Do the data confirm the following stereotypes? Provide a reasoned answer (data, figure, result sentence) for each question.**

```{r snore-analysis}

library(ggplot2)
library(dplyr)

# 1) Are snorers fatter? (weight ~ snore)
ggplot(snore, aes(x = snore, y = weight)) +
  geom_jitter(width = 0.2, alpha = 0.7, size = 2) +
  stat_summary(fun = median, geom = "crossbar", width = 0.5,
               colour = "red", fatten = 2) +
  labs(x = "Snoring status (O = yes, N = no)", y = "Weight (kg)",
       title = "Weight by snoring status") +
  theme_minimal(base_size = 14)

wilcox.test(weight ~ snore, data = snore)

# 2) Do snorers drink more? (alcool ~ snore)
ggplot(snore, aes(x = snore, y = alcool)) +
  geom_jitter(width = 0.2, alpha = 0.7, size = 2) +
  stat_summary(fun = median, geom = "crossbar", width = 0.5,
               colour = "red", fatten = 2) +
  labs(x = "Snoring status (O = yes, N = no)", y = "Alcohol score",
       title = "Alcohol by snoring status") +
  theme_minimal(base_size = 14)

wilcox.test(alcool ~ snore, data = snore)

# 3) Do snorers drink or smoke more? // wasnt 100% sure of this one, chose to interpret it as a combined question but could be 2 separate ones. english is hard. 
# Subset to snorers only
snorers <- snore %>% filter(snore == "O")

# yes/no alcool
snorers <- snorers %>%
  mutate(drink_yes = ifelse(alcool > 0, "Yes", "No"),
         smoke_yes = ifelse(tabac == "O", "Yes", "No"))

# Prevalence
prop.table(table(snorers$drink_yes))
prop.table(table(snorers$smoke_yes))

# Paired test (same people measured on both)
tab <- table(snorers$drink_yes, snorers$smoke_yes)
mcnemar.test(tab)

# Plot
prev <- data.frame(
  behavior = c("Drinkers", "Smokers"),
  prop = c(mean(snorers$drink_yes == "Yes"),
           mean(snorers$smoke_yes == "Yes"))
)

ggplot(prev, aes(x = behavior, y = prop)) +
  geom_col(fill = "grey40") +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Prevalence among snorers",
       x = NULL, y = "Prevalence") +
  theme_minimal(base_size = 14)


# 4) Are men fatter? (weight ~ sex)
ggplot(snore, aes(x = sex, y = weight)) +
  geom_jitter(width = 0.2, alpha = 0.7, size = 2) +
  stat_summary(fun = median, geom = "crossbar", width = 0.5,
               colour = "red", fatten = 2) +
  labs(x = "Sex (H = male, F = female)", y = "Weight (kg)",
       title = "Weight by sex") +
  theme_minimal(base_size = 14)

wilcox.test(weight ~ sex, data = snore)

# 5) Do women smoke less? (tabac × sex)
tabac_sex <- table(snore$sex, snore$tabac)
tabac_sex
chisq.test(tabac_sex)

# prevalence 
prop_smoke_sex <- snore %>%
  count(sex, tabac) %>%
  group_by(sex) %>%
  mutate(prop = n / sum(n))

ggplot(prop_smoke_sex[prop_smoke_sex$tabac == "O",], aes(x = sex, y = prop)) +
  geom_col(fill = "grey40") +
  scale_y_continuous(labels = function(z) paste0(100*z, "%")) +
  labs(x = "Sex (H = male, F = female)", y = "Prevalence",
       title = "Smoking prevalence by sex") +
  theme_minimal(base_size = 14)

# 6) Correlations among continuous variables (Spearman)
num_vars <- snore[, c("age", "weight", "height", "alcool")]
cor(num_vars, use = "pairwise.complete.obs", method = "spearman")
# Using cor() here to explore all pairwise correlations at once;
# earlier we used cor.test() for specific hypothesis tests (PANU vs SANU/EENU).

# Spearman correlation heatmap
cm <- cor(num_vars, use = "pairwise.complete.obs", method = "spearman")
cm_long <- as.data.frame(as.table(cm))
names(cm_long) <- c("Var1", "Var2", "rho")

ggplot(cm_long, aes(Var1, Var2, fill = rho)) +
  geom_tile(color = "white") +
  geom_text(aes(label = sprintf("%.2f", rho)), size = 3) +
  scale_fill_gradient2(limits = c(-1, 1), midpoint = 0) +
  labs(x = NULL, y = NULL, fill = "Spearman ρ",
       title = "Spearman correlations among continuous variables") +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```




Normality could not be assumed in the subgroups, particularly for skewed variables such as alcohol consumption, so we used non-parametric tests (Mann-Whitney, McNemar, chi-square, Spearman).

For comparisons of continuous variables between two independent groups (e.g., snorers vs non-snorers, men vs women), we used the Wilcoxon rank-sum test (Mann-Whitney U), the non-parametric analogue of the two-sample t-test (McDonald, 2014).

Categorical associations between independent groups (e.g., sex × smoking) were examined with chi-square tests of independence (McDonald, 2014). For paired categorical comparisons within the same individuals (e.g., drinking vs smoking prevalence among snorers), we used McNemar’s test (McNemar, 1947).
However, we treated alcohol as a yes/no variable (any drinking vs none), to make it comparable with smoking. We didn’t use the number of drinks per week, since there isn’t a clear cutoff (e.g., is 1 drinks a week really drinking ?), and the goal was just to compare prevalence.


Correlations between continuous variables were assessed with Spearman’s rank correlation, a non-parametric alternative to Pearson’s correlation (McDonald, 2014).


Results :

- Snorers were not heavier than non-snorers (W = 1154, p = 0.91).
- Snorers consumed significantly more alcohol than non-snorers (W = 788, p = 0.009).
- Among snorers, drinking (74%) tended to be more prevalent than smoking (57%), but this difference did not reach statistical significance (McNemar χ²(1) = 3.13, p = 0.077).
- Men and women did not differ significantly in weight (W = 893.5, p = 0.73).
- Women were significantly less likely to smoke than men (χ²(1) = 7.00, p = 0.008).


**From a more general perspective: Are there any correlations between variables?** 

As expected, weight and height were very strongly correlated (ρ ≈ 0.93). Other associations were weak, suggesting that in this dataset age and alcohol consumption were not closely related to body size.

Reference :

- McNemar, Q. (1947). Note on the sampling error of the difference between correlated proportions or percentages. Psychometrika, 12(2), 153–157.

# Epilogue: beyond the scope of this series
Finally, some of you may want to go beyond the scope of this series with new questions, such as:

**Can you predict the value of one variable from the others? (linear regression, logistic regression, etc.)** 
**Can you classify individuals based on their variables? (clustering, PCA, etc.)**

To go a bit further, we could try predicting one variable from the others with regression, or grouping people using clustering or PCA. That said : just because two things move together doesn’t mean one causes the other. Correlation is not causation ("La statistique expliquée à mon chat", youtube.com/watch?time_continue=180&v=aOX0pIwBCvw&source_ve_path=Mjg2NjY).

These tools are interesting to explore patterns, but they only make sense if we know why we’re using them.

Note on LLM use :
Some parts of this notebook were written with the help of an LLM (GPT-5 stand alone & Copilot GPT), both mainly for building some of the plots and/or debugging them and for some special formatting (latex).
Surprisingly, it was also really efficient at finding freely available studies and resources (mainly books in PDF), but it can introduce a strong confirmation bias depending on what I’m actually looking for. Also used for formatting on the notebook and/or the readme file.

type of prompts used : 
"Adapt this code to generate dot plots instead of boxplots.”
“Correct this paragraph and make it shorter, keeping the same tone : ”
“Explain why R gives a warning about ties in the Wilcoxon test.”
"Find me references for chi-square, and Spearman correlation tests.”
“Look into the literature for justification of using spaghetti plots with boxplots in small samples.”

